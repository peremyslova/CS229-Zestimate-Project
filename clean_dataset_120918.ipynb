{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and normalize data. Do unit conversion. Create new features. Come up with reasonably sized feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script deals with all data cleaning, imputation and feature engineering\n",
    "\n",
    "## DO NOT RUN!!!\n",
    "\n",
    "## Please don't run this script as it's very irregular and only meant for information purposes: there's a lot of comments throughout\n",
    "\n",
    "## It creates and saves short feature list for both regression and classification tasks\n",
    "\n",
    "## There are 52 columns 3 of which are not features: Sold Price, List Price and DOM\n",
    "\n",
    "## All numerical variables are standardized (zero mean and unit standard deviation)\n",
    "\n",
    "## All categorical variables (GST Incl, Title to Land, District, Address_IsPH) are converted to numerical using one-hot encoding: 2-level variables (GST Incl, Address_IsPH) get one column each, other two get as many columns as they have levels: e.g. District 0, District 1, ... District 32 (27 out of 35 total as some districts fall on water). Every newly converted column has two values: 0 and 1\n",
    "\n",
    "## No variables contain NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('data/downtown_2016-01-01_2016-03-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2016-04-01_2016-07-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2016-08-01_2016-12-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2017-01-01_2017-03-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2017-04-01_2017-07-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2017-08-01_2017-12-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2018-01-01_2018_03-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2018-04-01_2018-08-31.csv', encoding='ISO-8859-1'),\n",
    "    pd.read_csv('data/downtown_2018-09-01_2018-11-12.csv', encoding='ISO-8859-1')\n",
    "])\n",
    "# save original df\n",
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list variable types\n",
    "# commented out as it takes several minutes to check dtypes of all of df.shape data points\n",
    "#dtypes = []\n",
    "#for r in range(len(df)):\n",
    "#    dtypes.append(set(df.apply(lambda x: type(x.values[r]), axis=0).values))\n",
    "#var_dtypes = list(set([item for sublist in dtypes for item in sublist]))\n",
    "#var_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and converting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(c):\n",
    "    if type(c) == str:\n",
    "        return c.replace('$', '').replace(',', '').strip()\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "def clean_number(n):\n",
    "    if type(n) == str:\n",
    "        return n.replace(',', '').strip()\n",
    "    elif type(n) == int:\n",
    "        return n\n",
    "    elif type(n) == float:\n",
    "        return n\n",
    "\n",
    "def booleanize(s):\n",
    "    if type(s) == str:\n",
    "        return {\n",
    "            'yes': True,\n",
    "            'y': True,\n",
    "            'no': False,\n",
    "            'n': False}.get(s.lower(), False) # Should this be np.NaN?\n",
    "    elif type(s) == float:\n",
    "        if s is np.nan:\n",
    "            return s\n",
    "\n",
    "        print(type(s), s)\n",
    "        return np.NaN\n",
    "\n",
    "def feet_to_inches(s):\n",
    "    if type(s) == str:\n",
    "        s = re.sub('^\\'', '', s)\n",
    "        s = re.sub('\\'$', '', s)\n",
    "        \n",
    "        components = s.split('\\'')\n",
    "        if len(components) == 0:\n",
    "            return 0\n",
    "        elif len(components) == 1 and len(components[0]) > 0:\n",
    "            return 12 * int(components[0])\n",
    "        elif len(components) > 1:\n",
    "            feet = 0\n",
    "            inches = 0\n",
    "            if len(components[1]) > 0:\n",
    "                inches = int(components[1])\n",
    "            if len(components[0]) > 0:\n",
    "                feet = int(components[0])\n",
    "            else:\n",
    "                print('ERROR: ', s)\n",
    "            return 12 * int(components[0]) + inches\n",
    "        else:\n",
    "            print('ERROR: ', s)\n",
    "    elif type(s) == float:\n",
    "        if s is np.nan:\n",
    "            return s\n",
    "\n",
    "        # print(type(s), s)\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First remove rows with missing target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10605, 239)\n",
      "(6833, 239)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.loc[~pd.isnull(df['Sold Price'])]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove MLS ID duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6826, 239)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset='ML #', keep='first', inplace=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLS ID as dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('ML #', drop=True, inplace=True)\n",
    "df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[pd.isnull(df['View']), 'View - Specify'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['View'] == 'No', 'View - Specify'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['View'] == 'Yes', 'View - Specify'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new column with view as ordinal variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['View_Score'] = 0.0\n",
    "# assign nans if both 'View' and 'View - Specify' are nans\n",
    "df.loc[pd.isnull(df['View']) & pd.isnull(df['View - Specify']), 'View_Score'] = np.nan\n",
    "# assign 0.5 if either of 'View' and 'View - Specify' have non-negative values\n",
    "df.loc[pd.isnull(df['View']) & \\\n",
    "(~pd.isnull(df['View - Specify']) & (df['View - Specify'] != 'No') & (df['View - Specify'] != 'none')),\\\n",
    "              'View_Score'] = 0.5\n",
    "#\n",
    "df.loc[(df['View'] == 'No') & ((df['View - Specify'] != 'No') & (df['View - Specify'] != 'none')),\\\n",
    "              'View_Score'] = 0.5\n",
    "#\n",
    "df.loc[df['View'] == 'Yes',\\\n",
    "              'View_Score'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view description in lower case\n",
    "view_descr = df['View - Specify'].apply(lambda x: x.lower() if type(x) == str else '')\n",
    "# unique values\n",
    "view_descr_values = view_descr.value_counts(dropna=False).index.values\n",
    "# compose a vocabulary of view specifics\n",
    "view_vocab = []\n",
    "for value in view_descr_values:\n",
    "    view_vocab.append(re.split('[\\s]*\\W', value))\n",
    "view_vocab = [item for sublist in view_vocab for item in sublist]\n",
    "view_vocab = list(set(view_vocab))\n",
    "# sorted(view_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2224871    COAL HARBOUR, YACHT CLUB & CIT\n",
       "Name: View - Specify, dtype: object"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check view description by a word present in it\n",
    "df.loc[view_descr.str.contains('yacht'), 'View - Specify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose dict of words representative of a view\n",
    "view_cat = {'water':['aquabus', 'bay', 'beach', 'boats', 'bridge', 'bridges', 'eng', 'english', 'englishbay', \n",
    "                     'englisth', 'englsih', 'gate', 'habour', 'harb', 'harbaour', 'harbor', 'harbou', \n",
    "                     'harbour', 'harbours', 'hbour', 'hbr', 'hrbr', 'inle', 'inlet', 'intel', 'isand', 'isl',\n",
    "                     'island', 'islnd', 'lagoon', 'lgoon', 'lions', 'marina', 'marinas', 'marinaside', 'marine',\n",
    "                     'ocea', 'ocean', 'oceanfront', 'oceans', 'ocrean', 'river', 'riviera', 'sea', 'seawall',\n",
    "                     'shor', 'shore', 'wate', 'water', 'waterfront', 'watert', 'waterview', 'waterviews', \n",
    "                     'wter', 'wtr', 'wview', 'yacht'],\n",
    "            'mountains':['mnt', 'mntn', 'mntns', 'mnts', 'mouintains', 'mounatin', 'mount', 'mountai', \n",
    "                         'mountain', 'mountains', 'mountainview', 'mountan', 'mountbaker', 'mountian', \n",
    "                         'mountians', 'moutain', 'mt', 'mtn', 'mtns', 'mts', 'peaks'],\n",
    "            'park-creek':['barnes', 'barnespark', 'barns',  'cr', 'cree', 'creeek', 'creek', 'creen', 'crek', \n",
    "                          'crk', 'fales', 'false', 'falsecreek', 'garden', 'gardens', 'george', 'greek', \n",
    "                          'green', 'greenery', 'greenspace', 'park', 'parks', 'parq', 'pk', 'poark', 'stanely', \n",
    "                          'stanl', 'stanley', 'stanleyp', 'stanly', 'stantley', 'tree', 'treed', 'trees', \n",
    "                          'treetop', 'treetops'],\n",
    "            'urban':['arena', 'artgallery', 'atrium', 'chinatown', 'church', 'churches', 'cit', 'cities', \n",
    "                    'city', 'cityscape', 'cityscapes', 'cityview', 'district', 'dntwn', 'down', 'downto', \n",
    "                    'downtown', 'dowtown', 'dt', 'dtown', 'heritage', 'historic', 'historical', 'gastown',\n",
    "                    'landmarks', 'midtown', 'pictures', 'planetarium', 'plaza', 'roundhouse', 'stadium',\n",
    "                    'sky', 'skyline', 'skylines', 'town', 'urban', 'van', 'vancouver', 'vanhattan', 'yale', \n",
    "                    'yalet', 'yaletown', 'back', 'court', 'courthouse', 'courts', 'courtyard', 'coutryard',\n",
    "                    'pond', 'pool', 'poole', 'urban', 'yard'],\n",
    "            'panoramic':['180', '180deg', '180degrees', '270', 'amazing', 'awesome', 'beautiful', 'breathtaking',\n",
    "                         'bustling', 'dazzling', 'epic', 'excellent', 'exceptional', 'expansive', 'exposure',\n",
    "                         'endless', 'fabulous', 'fantastic', 'gorgeous', 'gorgous', 'great', 'immaculate',\n",
    "                         'incredible', 'iconic', 'lovely', 'lush', 'magnificent', 'mesmerizing', 'nice',\n",
    "                         'panaramic', 'panaromic', 'panorama', 'panoramic', 'outstanding', 'pleasant', \n",
    "                         'pretty', 'roof', 'rooftop', 'rooftops', 'spectacular', 'stunning', 'sunset',\n",
    "                         'sunsets', 'sutnning', 'sweeping', 'unbeatable', 'unblocked', 'unobstr', 'unobstruc',\n",
    "                         'unobstruct', 'unobstructed', 'unobsturcted'],\n",
    "            'partial':['parial', 'part', 'partial', 'partially', 'partly', 'peak', 'peakaboo', 'peaky', \n",
    "                       'peek', 'peekabo', 'peekaboo', 'pick', 'portion']\n",
    "            } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign View_Score following this convention\n",
    "If property view description contains one of the words in a category, it accumulates corresponding score: 'water' and 'mountains' get 2.0 points, 'park-creek' gets 1.5 points, 'urban' gets 1.0 points. Finally, accumulated score gets increased/decreased by 50% if it falls in one of two quality factors: 'panoramic' and 'partial'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.loc[~pd.isnull(df['View_Score'])].index:\n",
    "    views = re.split('[\\s]*\\W', view_descr.loc[ind].lower())\n",
    "    if len(list(set(views) & set(view_cat['water']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] += 2.0\n",
    "    if len(list(set(views) & set(view_cat['mountains']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] += 2.0\n",
    "    if len(list(set(views) & set(view_cat['park-creek']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] += 1.5\n",
    "    if len(list(set(views) & set(view_cat['urban']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] += 1.0\n",
    "    if len(list(set(views) & set(view_cat['panoramic']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] *= 1.5\n",
    "    if len(list(set(views) & set(view_cat['partial']))) > 0:\n",
    "        df.loc[ind, 'View_Score'] *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreykoch/anaconda3/lib/python3.6/site-packages/numpy/lib/histograms.py:754: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/andreykoch/anaconda3/lib/python3.6/site-packages/numpy/lib/histograms.py:755: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['View_Score'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do: Address has to be unified: get rid of apt. #, then it will have less values, and properties could be clusterized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S/A is not very accurate as it can  have different values for the same address, consider dropping it. 'Complex/Subdivision' could be a better location identifier but it requires further normalization. 'Address' seems to be more straightforward and more precise location identifier; after removing apt# it will be more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VVWDT    3001\n",
       "VVWYA    1805\n",
       "VVWWE    1424\n",
       "VVWCB     596\n",
       "Name: S/A, dtype: int64"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['S/A'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GST Incl'] = df['GST Incl'].apply(booleanize).astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_columns = ['List Price', 'Sold Price', 'Sold Price per SqFt', 'Gross Taxes', 'Prev Price', 'Price',\n",
    "                    'Price Per SQFT', 'Sold Price Per SQFT', 'Strata Maint Fee']\n",
    "for col in currency_columns:\n",
    "    df[col] = df[col].apply(clean_currency).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotFlArea'] = df['TotFlArea'].apply(clean_number).astype(np.float)\n",
    "df['Units in Development'] = df['Units in Development'].apply(clean_number).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['For Tax Year'] == 216] = 2016\n",
    "df[df['For Tax Year'] == 2105] = 2015\n",
    "df[df['For Tax Year'] == 0] = np.NaN\n",
    "#for i in range(1, 29):\n",
    "#    df['Room {} Dimension 1'.format(i)] = df['Room {} Dimension 1'.format(i)].apply(feet_to_inches).astype(np.float)\n",
    "#    df['Room {} Dimension 2'.format(i)] = df['Room {} Dimension 2'.format(i)].apply(feet_to_inches).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 239)"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up outlier data\n",
    "df = df.loc[df['TotFlArea'] >= 250]\n",
    "df = df.loc[df['Yr Blt'] < 9999]\n",
    "df = df.loc[df['Age'] < 999]\n",
    "df = df.loc[df['Price Per SQFT'] < 7500]\n",
    "# Leave this last one commented out because we still want to include houses that haven't been sold further in the pipeline\n",
    "# df_clean = df_clean[df_clean['Sold Price Per SQFT'] < 7500]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilization of fields Room Dimension, Type, Level  \n",
    "The problem with fields 'Room # Dimension ##', 'Room # Level' and 'Room # Type' is that often same Room # points to completely different types of rooms in different houses. So these columns are not consistent across rows, and using them as they are will be counter-productive. Information in these fields, however, can be mapped by 'Room # Type' to the most common types of rooms: living room, kitchen, dining room, foyer, master bedroom, second bedroom, third bedroom, den, family room, storage, office. 'Room # Dimension 1' and 'Room # Dimension 2' can be combined in one column 'Room # FlArea', and in the end for each (shortlist) room type XXX we'll have two columns: 'Room Type XXX Level' and 'Room Type XXX FlArea'.\n",
    "\n",
    "### For now, though, I'm removing all these fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 127)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indrop = []\n",
    "for i in range(1, 29):\n",
    "    indrop = np.append(indrop, np.where(df.columns.str.contains(''.join(['Room ', str(i), ' ']))))\n",
    "indrop = [int(num) for num in indrop]\n",
    "#\n",
    "df = df.drop(df.columns[indrop], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar situation with the fields starting with 'Bath'. Remove them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 91)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[df.columns.str.startswith('Bath')], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['Foundation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean.columns[df_clean.columns.str.contains('Room') & df_clean.columns.str.contains('Dimension')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['Room 1 Dimension 1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['Room 10 Dimension 1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Tot BR'], df['# Rms']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "'Pics',\n",
    "'Client Hit Count',\n",
    "'Collapse Date',\n",
    "'Floorplan URL',\n",
    "'Municipality',\n",
    "'Neighborhood Code',\n",
    "'Owner Name',\n",
    "'Previous Exp Date',\n",
    "'Previous Price Sys',\n",
    "'Protected Owner Name',\n",
    "'Room Type Search',\n",
    "'Worldproperties.com',\n",
    "'Display Addr on Internet',\n",
    "'S. Prc Exclsv of GST/HST?',\n",
    "'Pub Listing on Internet',\n",
    "'VOW Comment',\n",
    "'Floor Area - Unfinished',\n",
    "'Area',\n",
    "'Dwelling Classification',\n",
    "'City',\n",
    "'Class',\n",
    "'View',\n",
    "'View - Specify',\n",
    "'First Withdrawn Date',\n",
    "'Listing Entered By',\n",
    "'Listing Visibility Type',\n",
    "'Mgmt. Co Phone#',\n",
    "'No. Floor Levels',\n",
    "'Prev Status',\n",
    "'Foundation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 61)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove columns\n",
    "df = df.drop(columns_to_remove, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove2 = [\n",
    "'Status',\n",
    "'S/A',\n",
    "'Locker',\n",
    "'Cats',\n",
    "'Dogs',\n",
    "'Days On MLS',\n",
    "'# or % of Rentals Allowed',\n",
    "'Cancel Effective Date',\n",
    "'Cancel Protection Date',\n",
    "'Commission',\n",
    "'Dist to School/School Bus',\n",
    "'Distance to Pub/Rapid Tr',\n",
    "'Internet Remarks',\n",
    "'Legal Description',\n",
    "'Prev Commission',\n",
    "'Prev Price',\n",
    "'Price', \n",
    "'Price Per SQFT',\n",
    "'Public Remarks',\n",
    "'Realtor Remarks',\n",
    "'For Tax Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 40)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove columns\n",
    "df = df.drop(columns_to_remove2, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove3 = [\n",
    "'List Date', \n",
    "'Sold Date',  \n",
    "'Price Date',\n",
    "'Confirm Sold Date',\n",
    "'Expiry Date',\n",
    "'Status Change Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 33)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove columns\n",
    "df = df.drop(columns_to_remove3, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different values in 'Zoning' might mean the same. We can leave this field for now and see if it's working.\n",
    "\n",
    "'Commission' has pretty much same terms. If have time, might extract numbers. Remove for now.\n",
    "\n",
    "'Dist to School/School Bus' and 'Distance to Pub/Rapid Tr' have either (mostly) nans or something like 1 block/close/in front. Not too informative since everything is nearby in downtown. Remove for now.\n",
    "\n",
    "'Internet Remarks' presents many possibilities for feature mining. Might leave it for after class project improvement. Remove for now.\n",
    "\n",
    "'Legal Description' also could have some value after processing. Remove for now.\n",
    "\n",
    "'Listing Entered By' is removed, likely not relevant.\n",
    "\n",
    "'No. Floor Levels' is removed as too many nans.\n",
    "\n",
    "'Public Remarks' also rich in free-form text info. Remove for now.\n",
    "\n",
    "'Realtor Remarks' is removed for now.\n",
    "\n",
    "'For Tax Year' is removed for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corind = ~pd.isnull(df['Parking Places - Covered']) & ~pd.isnull(df['TotalPrkng'])\n",
    "#np.corrcoef(df.loc[corind, 'Parking Places - Covered'], df.loc[corind, 'TotalPrkng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['# of Pets'] == 'No Restriction', '# of Pets'] = str(3)\n",
    "df['# of Pets'] = df['# of Pets'].apply(lambda x: int(x) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Zoning'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Approx.Yr of Renos/Addns'] == 9999, 'Approx.Yr of Renos/Addns'] = np.nan\n",
    "#\n",
    "df.loc[pd.isnull(df['Fireplaces']), 'Fireplaces'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 3 nans by most frequent value\n",
    "df.loc[pd.isnull(df['Zoning']), 'Zoning'] = 'CD-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 8 nans by median value, need to use finer replacement\n",
    "df.loc[pd.isnull(df['Gross Taxes']), 'Gross Taxes'] = np.nanmedian(df['Gross Taxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 1 nan by median value\n",
    "df.loc[pd.isnull(df['Strata Maint Fee']), 'Strata Maint Fee'] = np.nanmedian(df['Strata Maint Fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two parking fields and replace nans by median\n",
    "df.loc[pd.isnull(df['TotalPrkng']), 'TotalPrkng'] = \\\n",
    "df.loc[pd.isnull(df['TotalPrkng']), 'Parking Places - Covered']\n",
    "df.loc[pd.isnull(df['TotalPrkng']), 'TotalPrkng'] = np.nanmedian(df['TotalPrkng'])\n",
    "df = df.drop(['Parking Places - Covered'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 'Full Baths' and 'Half Baths'\n",
    "df['Baths'] = df['Full Baths'] + df['Half Baths']*0.5\n",
    "df = df.drop(['Full Baths', 'Half Baths'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nans in View_Score by median value\n",
    "df.loc[pd.isnull(df['View_Score']), 'View_Score'] = np.nanmedian(df['View_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'Yr Blt' as it has same info as 'Age'\n",
    "df = df.drop(['Yr Blt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PicCount', 'Address', 'List Price', 'Sold Price', 'Tot BR',\n",
       "       'Tot Baths', 'TotFlArea', 'Age', 'TotalPrkng',\n",
       "       'Sold Price per SqFt', '# of Pets', '# Rms',\n",
       "       'Approx.Yr of Renos/Addns', 'Complex/Subdivision', 'Fireplaces',\n",
       "       'Gross Taxes', 'GST Incl', 'Mgmt. Co Name', 'Postal Code',\n",
       "       'Rain Screen', 'Title to Land', 'Sold Price Per SQFT',\n",
       "       'SP/LP Ratio', 'SP/OLP Ratio', 'Stories in Building',\n",
       "       'Strata Maint Fee', 'Units in Development', 'Zoning', 'View_Score',\n",
       "       'Baths'], dtype=object)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display remaining columns\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Pets has 5112 nans\n",
      "Approx.Yr of Renos/Addns has 5428 nans\n",
      "Complex/Subdivision has 1308 nans\n",
      "Mgmt. Co Name has 789 nans\n",
      "Rain Screen has 5647 nans\n",
      "Stories in Building has 4421 nans\n",
      "Units in Development has 3044 nans\n"
     ]
    }
   ],
   "source": [
    "# which columns have nans\n",
    "for col in df.columns:\n",
    "    sumnan = sum(pd.isnull(df[col]))\n",
    "    if sumnan > 0:\n",
    "        print(''.join([col, ' has ', str(sumnan), ' nans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['# of Pets', 'Approx.Yr of Renos/Addns', \\\n",
    "              'Stories in Building', 'Units in Development', 'Sold Price per SqFt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex/Subdivision has 1308 nans\n",
      "Mgmt. Co Name has 789 nans\n",
      "Rain Screen has 5647 nans\n"
     ]
    }
   ],
   "source": [
    "# no columns have nans now\n",
    "for col in df.columns:\n",
    "    sumnan = sum(pd.isnull(df[col]))\n",
    "    if sumnan > 0:\n",
    "        print(''.join([col, ' has ', str(sumnan), ' nans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PicCount', 'Address', 'List Price', 'Sold Price', 'Tot BR',\n",
       "       'Tot Baths', 'TotFlArea', 'Age', 'TotalPrkng', '# Rms',\n",
       "       'Complex/Subdivision', 'Fireplaces', 'Gross Taxes', 'GST Incl',\n",
       "       'Mgmt. Co Name', 'Postal Code', 'Rain Screen', 'Title to Land',\n",
       "       'Sold Price Per SQFT', 'SP/LP Ratio', 'SP/OLP Ratio',\n",
       "       'Strata Maint Fee', 'Zoning', 'View_Score', 'Baths'], dtype=object)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display remaining columns\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 25)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Address to location: create geographic and cartesian coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygeocoder import Geocoder\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"root\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "#------------------ CONFIGURATION -------------------------------\n",
    "\n",
    "# Set your Google API key here. \n",
    "# Even if using the free 2500 queries a day, its worth getting an API key since the rate limit is 50 / second.\n",
    "# With API_KEY = None, you will run into a 2 second delay every 10 requests or so.\n",
    "# With a \"Google Maps Geocoding API\" key from https://console.developers.google.com/apis/, \n",
    "# the daily limit will be 2500, but at a much faster rate.\n",
    "# Example: API_KEY = 'AIzaSyC9azed9tLdjpZNjg2_kVePWvMIBq154eA'\n",
    "#API_KEY = None\n",
    "# Backoff time sets how many minutes to wait between google pings when your API limit is hit\n",
    "BACKOFF_TIME = 0.5\n",
    "# Set your output file name here.\n",
    "output_filename = 'data/Geocode_Vancouver.csv'\n",
    "# Set your input file here\n",
    "input_filename = \"data/PPR-2015.csv\"\n",
    "# Specify the column name in your input data that contains addresses here\n",
    "address_column_name = \"Address\"\n",
    "# Return Full Google Results? If True, full JSON results from Google are included in output\n",
    "RETURN_FULL_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ DATA LOADING --------------------------------\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "data = pd.read_csv(input_filename, encoding='utf8')\n",
    "\n",
    "if address_column_name not in data.columns:\n",
    "\traise ValueError(\"Missing Address column in input data\")\n",
    "\n",
    "# Form a list of addresses for geocoding:\n",
    "# Make a big list of all of the addresses to be processed.\n",
    "addresses = data[address_column_name].tolist()\n",
    "\n",
    "# **** DEMO DATA / IRELAND SPECIFIC! ****\n",
    "# We know that these addresses are in Ireland, and there's a column for county, so add this for accuracy. \n",
    "# (remove this line / alter for your own dataset)\n",
    "addresses = (data[address_column_name] + ',' + data['County'] + ',Ireland').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ PROCESSING LOOP -----------------------------\n",
    "\n",
    "# Ensure, before we start, that the API key is ok/valid, and internet access is ok\n",
    "test_result = get_google_results(\"London, England\", API_KEY, RETURN_FULL_RESULTS)\n",
    "if (test_result['status'] != 'OK') or (test_result['formatted_address'] != 'London, UK'):\n",
    "    logger.warning(\"There was an error when testing the Google Geocoder.\")\n",
    "    raise ConnectionError('Problem with test results from Google Geocode - check your API key and internet connection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_results(address, api_key=None, return_full_response=False):\n",
    "    \"\"\"\n",
    "    Get geocode results from Google Maps Geocoding API.\n",
    "    \n",
    "    Note, that in the case of multiple google geocode reuslts, this function returns details of the FIRST result.\n",
    "    \n",
    "    @param address: String address as accurate as possible. For Example \"18 Grafton Street, Dublin, Ireland\"\n",
    "    @param api_key: String API key if present from google. \n",
    "                    If supplied, requests will use your allowance from the Google API. If not, you\n",
    "                    will be limited to the free usage of 2500 requests per day.\n",
    "    @param return_full_response: Boolean to indicate if you'd like to return the full response from google. This\n",
    "                    is useful if you'd like additional location details for storage or parsing later.\n",
    "    \"\"\"\n",
    "    # Set up your Geocoding url\n",
    "    geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?address={}\".format(address)\n",
    "    if api_key is not None:\n",
    "        geocode_url = geocode_url + \"&key={}\".format(api_key)\n",
    "        \n",
    "    # Ping google for the reuslts:\n",
    "    results = requests.get(geocode_url)\n",
    "    # Results will be in JSON format - convert to dict using requests functionality\n",
    "    results = results.json()\n",
    "    \n",
    "    # if there's no results or an error, return empty results.\n",
    "    if len(results['results']) == 0:\n",
    "        output = {\n",
    "            \"formatted_address\" : None,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"accuracy\": None,\n",
    "            \"google_place_id\": None,\n",
    "            \"type\": None,\n",
    "            \"postcode\": None\n",
    "        }\n",
    "    else:    \n",
    "        answer = results['results'][0]\n",
    "        output = {\n",
    "            \"formatted_address\" : answer.get('formatted_address'),\n",
    "            \"latitude\": answer.get('geometry').get('location').get('lat'),\n",
    "            \"longitude\": answer.get('geometry').get('location').get('lng'),\n",
    "            \"accuracy\": answer.get('geometry').get('location_type'),\n",
    "            \"google_place_id\": answer.get(\"place_id\"),\n",
    "            \"type\": \",\".join(answer.get('types')),\n",
    "            \"postcode\": \",\".join([x['long_name'] for x in answer.get('address_components') \n",
    "                                  if 'postal_code' in x.get('types')])\n",
    "        }\n",
    "        \n",
    "    # Append some other details:    \n",
    "    output['input_string'] = address\n",
    "    output['number_of_results'] = len(results['results'])\n",
    "    output['status'] = results.get('status')\n",
    "    if return_full_response is True:\n",
    "        output['response'] = results\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address_Unit#'] = df['Address'].apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address_IsPH'] = 0\n",
    "df.loc[df['Address_Unit#'].str.contains('PH'), 'Address_IsPH'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address_Street'] = df['Address'].apply(lambda x: ' '.join(x.split(' ')[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = (df['Address_Street'] + ',' + 'Vancouver,BC ' + df['Postal Code'] + ',Canada').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1333 W GEORGIA STREET,Vancouver,BC V6E 4V3,Canada',\n",
       " '1238 BURRARD STREET,Vancouver,BC V6Z 3E1,Canada',\n",
       " '1723 ALBERNI STREET,Vancouver,BC V6G 3G9,Canada',\n",
       " '1009 EXPO BOULEVARD,Vancouver,BC V6Z 2V9,Canada',\n",
       " '833 HOMER STREET,Vancouver,BC V6B 0H4,Canada',\n",
       " '111 W GEORGIA STREET,Vancouver,BC V6B 1T8,Canada',\n",
       " '1080 BROUGHTON STREET,Vancouver,BC V6G 2A8,Canada',\n",
       " '602 CITADEL PARADE,Vancouver,BC V6B 1X2,Canada',\n",
       " '161 W GEORGIA STREET,Vancouver,BC V6B 0K9,Canada',\n",
       " '950 CAMBIE STREET,Vancouver,BC V6B 5Y1,Canada']"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1333 W GEORGIA STREET,Vancouver,BC V6E 4V3,Canada'"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses_unique = list(set(addresses))\n",
    "len(addresses_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formatted_address': '1333 W Georgia St, Vancouver, BC V6E 4V3, Canada',\n",
       " 'latitude': 49.2889719,\n",
       " 'longitude': -123.1275315,\n",
       " 'accuracy': 'ROOFTOP',\n",
       " 'google_place_id': 'ChIJS5Z28IZxhlQRGXgQ4u6WzGI',\n",
       " 'type': 'premise',\n",
       " 'postcode': 'V6E 4V3',\n",
       " 'input_string': '1333 W GEORGIA STREET,Vancouver,BC V6E 4V3,Canada',\n",
       " 'number_of_results': 1,\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = get_google_results(addresses[0], API_KEY, RETURN_FULL_RESULTS)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed 50 of 119 address\n",
      "Completed 50 of 119 address\n",
      "Completed 50 of 119 address\n",
      "Completed 100 of 119 address\n",
      "Completed 100 of 119 address\n",
      "Completed 100 of 119 address\n",
      "Finished geocoding all addresses\n",
      "Finished geocoding all addresses\n",
      "Finished geocoding all addresses\n"
     ]
    }
   ],
   "source": [
    "#------------------ PROCESSING LOOP -----------------------------\n",
    "\n",
    "# Create a list to hold results\n",
    "results_1 = []\n",
    "# Go through each address in turn\n",
    "for address in addresses_1_unique:\n",
    "    # While the address geocoding is not finished:\n",
    "    geocoded = False\n",
    "    while geocoded is not True:\n",
    "        # Geocode the address with google\n",
    "        try:\n",
    "            geocode_result = get_google_results(address, API_KEY, return_full_response=RETURN_FULL_RESULTS)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Major error with {}\".format(address))\n",
    "            logger.error(\"Skipping!\")\n",
    "            geocoded = True\n",
    "            \n",
    "        # If we're over the API limit, backoff for a while and try again later.\n",
    "        if geocode_result['status'] == 'OVER_QUERY_LIMIT':\n",
    "            logger.info(\"Hit Query Limit! Backing off for a bit.\")\n",
    "            time.sleep(BACKOFF_TIME * 2) # sleep for 30 minutes\n",
    "            geocoded = False\n",
    "        else:\n",
    "            # If we're ok with API use, save the results\n",
    "            # Note that the results might be empty / non-ok - log this\n",
    "            if geocode_result['status'] != 'OK':\n",
    "                logger.warning(\"Error geocoding {}: {}\".format(address, geocode_result['status']))\n",
    "            #logger.debug(\"Geocoded: {}: {}\".format(address, geocode_result['status']))\n",
    "            results_1.append(geocode_result)           \n",
    "            geocoded = True\n",
    "\n",
    "    # Print status every 100 addresses\n",
    "    if len(results_1) % 50 == 0:\n",
    "        logger.info(\"Completed {} of {} address\".format(len(results_1), len(addresses_1_unique)))\n",
    "            \n",
    "    # Every 500 addresses, save progress to file(in case of a failure so you have something!)\n",
    "    #if len(results) % 100 == 0:\n",
    "    #    pd.DataFrame(results).to_csv(\"{}_bak\".format(output_filename))\n",
    "\n",
    "# All done\n",
    "logger.info(\"Finished geocoding all addresses\")\n",
    "# Write the full results to csv using the pandas library.\n",
    "pd.DataFrame(results_1).to_csv('data/Geocode_Vancouver_1.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>google_place_id</th>\n",
       "      <th>input_string</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>postcode</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROOFTOP</td>\n",
       "      <td>1355 Harwood St, Vancouver, BC V6E 3W3, Canada</td>\n",
       "      <td>ChIJaydaPyxyhlQR_urvTwhYRe8</td>\n",
       "      <td>1355 HARWOOD STREET,Vancouver,BC V6E 3W3,Canada</td>\n",
       "      <td>49.282083</td>\n",
       "      <td>-123.137655</td>\n",
       "      <td>1</td>\n",
       "      <td>V6E 3W3</td>\n",
       "      <td>OK</td>\n",
       "      <td>street_address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEOMETRIC_CENTER</td>\n",
       "      <td>Beatty St, Vancouver, BC V6Z 3C5, Canada</td>\n",
       "      <td>EihCZWF0dHkgU3QsIFZhbmNvdXZlciwgQkMgVjZaIDNDNS...</td>\n",
       "      <td>BEATTY STREET,Vancouver,BC V6Z 3C5,Canada</td>\n",
       "      <td>49.276226</td>\n",
       "      <td>-123.116019</td>\n",
       "      <td>1</td>\n",
       "      <td>V6Z 3C5</td>\n",
       "      <td>OK</td>\n",
       "      <td>route</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROOFTOP</td>\n",
       "      <td>1270 Robson St, Vancouver, BC V6E 1C1, Canada</td>\n",
       "      <td>ChIJdQzPSodxhlQR64HS2lozP9g</td>\n",
       "      <td>1270 ROBSON STREET,Vancouver,BC V6E 1C1,Canada</td>\n",
       "      <td>49.286580</td>\n",
       "      <td>-123.128161</td>\n",
       "      <td>1</td>\n",
       "      <td>V6E 1C1</td>\n",
       "      <td>OK</td>\n",
       "      <td>premise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy                               formatted_address  \\\n",
       "0           ROOFTOP  1355 Harwood St, Vancouver, BC V6E 3W3, Canada   \n",
       "1  GEOMETRIC_CENTER        Beatty St, Vancouver, BC V6Z 3C5, Canada   \n",
       "2           ROOFTOP   1270 Robson St, Vancouver, BC V6E 1C1, Canada   \n",
       "\n",
       "                                     google_place_id  \\\n",
       "0                        ChIJaydaPyxyhlQR_urvTwhYRe8   \n",
       "1  EihCZWF0dHkgU3QsIFZhbmNvdXZlciwgQkMgVjZaIDNDNS...   \n",
       "2                        ChIJdQzPSodxhlQR64HS2lozP9g   \n",
       "\n",
       "                                      input_string   latitude   longitude  \\\n",
       "0  1355 HARWOOD STREET,Vancouver,BC V6E 3W3,Canada  49.282083 -123.137655   \n",
       "1        BEATTY STREET,Vancouver,BC V6Z 3C5,Canada  49.276226 -123.116019   \n",
       "2   1270 ROBSON STREET,Vancouver,BC V6E 1C1,Canada  49.286580 -123.128161   \n",
       "\n",
       "   number_of_results postcode status            type  \n",
       "0                  1  V6E 3W3     OK  street_address  \n",
       "1                  1  V6Z 3C5     OK           route  \n",
       "2                  1  V6E 1C1     OK         premise  "
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo = pd.read_csv(output_filename, index_col=0)\n",
    "df_geo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>google_place_id</th>\n",
       "      <th>input_string</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>postcode</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROOFTOP</td>\n",
       "      <td>979 Expo Blvd, Vancouver, BC V6Z 2W1, Canada</td>\n",
       "      <td>ChIJu_YZZH1xhlQRLoCiFw1o56w</td>\n",
       "      <td>979 EXPO BOULEVARD,Vancouver,BC V6Z 3G8,Canada</td>\n",
       "      <td>49.275505</td>\n",
       "      <td>-123.115134</td>\n",
       "      <td>1</td>\n",
       "      <td>V6Z 2W1</td>\n",
       "      <td>OK</td>\n",
       "      <td>street_address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEOMETRIC_CENTER</td>\n",
       "      <td>Boathouse Mews, Vancouver, BC V6Z, Canada</td>\n",
       "      <td>ChIJ5f15mtdzhlQRJBz33vL3Ppc</td>\n",
       "      <td>188 BOATHOUSE MEWS,Vancouver,BC V6Z 2Z6,Canada</td>\n",
       "      <td>49.273633</td>\n",
       "      <td>-123.117505</td>\n",
       "      <td>1</td>\n",
       "      <td>V6Z</td>\n",
       "      <td>OK</td>\n",
       "      <td>route</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROOFTOP</td>\n",
       "      <td>37 Keefer Pl, Vancouver, BC V6B 0B8, Canada</td>\n",
       "      <td>ChIJBz0k-XpxhlQRicdAGCy-fK4</td>\n",
       "      <td>37 KEEFER PLACE,Vancouver,BC V6B 1P8,Canada</td>\n",
       "      <td>49.279486</td>\n",
       "      <td>-123.105337</td>\n",
       "      <td>1</td>\n",
       "      <td>V6B 0B8</td>\n",
       "      <td>OK</td>\n",
       "      <td>street_address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy                             formatted_address  \\\n",
       "0           ROOFTOP  979 Expo Blvd, Vancouver, BC V6Z 2W1, Canada   \n",
       "1  GEOMETRIC_CENTER     Boathouse Mews, Vancouver, BC V6Z, Canada   \n",
       "2           ROOFTOP   37 Keefer Pl, Vancouver, BC V6B 0B8, Canada   \n",
       "\n",
       "               google_place_id  \\\n",
       "0  ChIJu_YZZH1xhlQRLoCiFw1o56w   \n",
       "1  ChIJ5f15mtdzhlQRJBz33vL3Ppc   \n",
       "2  ChIJBz0k-XpxhlQRicdAGCy-fK4   \n",
       "\n",
       "                                     input_string   latitude   longitude  \\\n",
       "0  979 EXPO BOULEVARD,Vancouver,BC V6Z 3G8,Canada  49.275505 -123.115134   \n",
       "1  188 BOATHOUSE MEWS,Vancouver,BC V6Z 2Z6,Canada  49.273633 -123.117505   \n",
       "2     37 KEEFER PLACE,Vancouver,BC V6B 1P8,Canada  49.279486 -123.105337   \n",
       "\n",
       "   number_of_results postcode status            type  \n",
       "0                  1  V6Z 2W1     OK  street_address  \n",
       "1                  1      V6Z     OK           route  \n",
       "2                  1  V6B 0B8     OK  street_address  "
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo_1 = pd.read_csv('data/Geocode_Vancouver_1.csv', index_col=0)\n",
    "df_geo_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEOMETRIC_CENTER    72\n",
       "Name: accuracy, dtype: int64"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.loc[df_geo['type'] == 'route', 'accuracy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "route    72\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.loc[df_geo['accuracy'] == 'GEOMETRIC_CENTER', 'type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo['street_address'] = df_geo['input_string'].apply(lambda x: x.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_1['street_address'] = df_geo_1['input_string'].apply(lambda x: x.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = 0\n",
    "df['lon'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coord_miss'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Address_Street'].isin(df_geo.loc[df_geo['type'] == 'route', 'street_address']), 'coord_miss'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_1 = (df.loc[df['coord_miss'] == 0, 'Address_Street'] + ',' + 'Vancouver,BC ' +\\\n",
    "               df.loc[df['coord_miss'] == 0, 'Postal Code'] + ',Canada').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses_1_unique = list(set(addresses_1))\n",
    "len(addresses_1_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip in range(len(df_geo)):\n",
    "    if df_geo.loc[ip, 'type'] != 'route':\n",
    "        df.loc[df['Address_Street'] == df_geo.loc[ip, 'street_address'], 'lat'] = df_geo.loc[ip, 'latitude']\n",
    "        df.loc[df['Address_Street'] == df_geo.loc[ip, 'street_address'], 'lon'] = df_geo.loc[ip, 'longitude']\n",
    "    else:\n",
    "        for inp in df.loc[df['Address_Street'] == df_geo.loc[ip, 'street_address']].index:\n",
    "            df.loc[inp, 'Address_Street'] = ' '.join([df.loc[inp, 'Address_Unit#'],\\\n",
    "                                                      df.loc[inp, 'Address_Street']])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip in range(len(df_geo_1)):\n",
    "    df.loc[df['Address_Street'] == df_geo_1.loc[ip, 'street_address'], 'lat'] = df_geo_1.loc[ip, 'latitude']\n",
    "    df.loc[df['Address_Street'] == df_geo_1.loc[ip, 'street_address'], 'lon'] = df_geo_1.loc[ip, 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6808.000000\n",
       "mean       49.280270\n",
       "std         0.005127\n",
       "min        49.271566\n",
       "25%        49.276197\n",
       "50%        49.278899\n",
       "75%        49.283756\n",
       "max        49.293815\n",
       "Name: lat, dtype: float64"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lat'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6808.000000\n",
       "mean     -123.123196\n",
       "std         0.008370\n",
       "min      -123.146146\n",
       "25%      -123.128164\n",
       "50%      -123.124035\n",
       "75%      -123.117447\n",
       "max      -123.100085\n",
       "Name: lon, dtype: float64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert geographic to cartesian coordinates\n",
    "R = 6.371e+6\n",
    "deg2rad = np.pi/180\n",
    "lat_ref = df['lat'].mean()\n",
    "lat_min = df['lat'].min()\n",
    "lon_min = df['lon'].min()\n",
    "df['X'] = (df['lon'] - lon_min)*(R*deg2rad*np.cos(lat_ref*deg2rad))\n",
    "df['Y'] = (df['lat'] - lat_min)*(R*deg2rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.271565700000004, 49.2938151]\n",
      "[-123.1461456, -123.10008549999999]\n"
     ]
    }
   ],
   "source": [
    "print([df['lat'].min(), df['lat'].max()])\n",
    "print([df['lon'].min(), df['lon'].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 2474.020400885418]\n",
      "[0.0, 3341.156303747171]\n"
     ]
    }
   ],
   "source": [
    "print([df['Y'].min(), df['Y'].max()])\n",
    "print([df['X'].min(), df['X'].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "49.271565700000004, -123.1461456\n",
    "49.2938151, -123.10008549999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign homes to squares of approximately 500x500m\n",
    "xsq = 7; ysq = 5\n",
    "dx = df['X'].max()/xsq\n",
    "dy = df['Y'].max()/ysq\n",
    "df['District'] = np.nan\n",
    "distr = 0\n",
    "for ix in range(xsq):\n",
    "    for iy in range(ysq):\n",
    "        distr = ix*ysq + iy\n",
    "        xmin = ix*dx; xmax = (ix+1)*dx\n",
    "        ymin = iy*dy; ymax = (iy+1)*dy\n",
    "        if ix == (xsq - 1):\n",
    "            xmax += 100\n",
    "        if iy == (ysq - 1):\n",
    "            ymax += 100\n",
    "        df.loc[(df['X'] >= xmin) & (df['X'] < xmax) & (df['Y'] >= ymin) & (df['Y'] < ymax) , 'District'] = str(distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21    810\n",
       "16    800\n",
       "11    611\n",
       "10    502\n",
       "15    464\n",
       "18    421\n",
       "26    388\n",
       "20    372\n",
       "13    345\n",
       "22    258\n",
       "17    229\n",
       "14    196\n",
       "27    188\n",
       "8     155\n",
       "7     141\n",
       "9     111\n",
       "6     108\n",
       "3      97\n",
       "31     92\n",
       "12     88\n",
       "25     85\n",
       "4      78\n",
       "32     76\n",
       "5      68\n",
       "23     62\n",
       "19     34\n",
       "2      29\n",
       "Name: District, dtype: int64"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['District'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['District'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Taxes/TotFlArea\n",
    "df['Taxes/TotFlArea'] = df['Gross Taxes']/df['TotFlArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PicCount', 'Address', 'List Price', 'Sold Price', 'Tot BR',\n",
       "       'Tot Baths', 'TotFlArea', 'Age', 'TotalPrkng', '# Rms',\n",
       "       'Complex/Subdivision', 'Fireplaces', 'Gross Taxes', 'GST Incl',\n",
       "       'Mgmt. Co Name', 'Postal Code', 'Rain Screen', 'Title to Land',\n",
       "       'Sold Price Per SQFT', 'SP/LP Ratio', 'SP/OLP Ratio',\n",
       "       'Strata Maint Fee', 'Zoning', 'View_Score', 'Baths',\n",
       "       'Address_Unit#', 'Address_Street', 'Address_IsPH', 'lat', 'lon',\n",
       "       'coord_miss', 'X', 'Y', 'District', 'DOM', 'Taxes/TotFlArea'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display remaining columns\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "columns_to_remove4 = [\n",
    "'Complex/Subdivision', \n",
    "'Mgmt. Co Name',  \n",
    "'Rain Screen',\n",
    "'Zoning']\n",
    "# remove columns\n",
    "df = df.drop(columns_to_remove3, axis=1)\n",
    "df.shape\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Rain Screen\n",
    "df = df.drop('Rain Screen', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize numerical variables. Convert categorical variables to binary using one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['PicCount', 'List Price', 'Sold Price', 'Tot BR',\n",
    "       'Tot Baths', 'TotFlArea', 'Age', 'TotalPrkng', '# Rms',\n",
    "       'Fireplaces', 'Gross Taxes', 'Taxes/TotFlArea', 'Strata Maint Fee', 'View_Score', 'Baths']\n",
    "x_num = df[numeric_cols].values\n",
    "scaler = StandardScaler()\n",
    "x_num = scaler.fit_transform(x_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with cat. variables having too many values is that one-hot encoding creates columns for each of them. So I'm leaving 'Address' out until we at least reduce it to street number. For the same reason I'm leaving out 'Complex/Subdivision' and 'Mgmt. Co Name'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address has 6277 values\n",
      "Address_Street has 571 values\n",
      "Complex/Subdivision has 1385 values\n",
      "GST Incl has 2 values\n",
      "Mgmt. Co Name has 859 values\n",
      "Postal Code has 577 values\n",
      "Title to Land has 7 values\n",
      "Zoning has 169 values\n",
      "District has 27 values\n",
      "DOM has 184 values\n",
      "10058\n"
     ]
    }
   ],
   "source": [
    "categoric_cols = ['Address', 'Address_Street', 'Complex/Subdivision', 'GST Incl', 'Mgmt. Co Name', 'Postal Code',\\\n",
    "                  'Title to Land', 'Zoning', 'District', 'DOM']\n",
    "val_cnt_tot = 0\n",
    "for col in categoric_cols:\n",
    "    val_cnt = len(df[col].value_counts())\n",
    "    print(''.join([col, ' has ', str(val_cnt), ' values']))\n",
    "    val_cnt_tot += val_cnt\n",
    "print(val_cnt_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17+2+577+3+7+169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreykoch/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# use only these categorical variables\n",
    "categoric_cols = ['GST Incl', 'Title to Land', 'District']\n",
    "cat = df[categoric_cols]\n",
    "cat.fillna('NA', inplace=True)\n",
    "x_cat = cat.to_dict(orient='records')\n",
    "vectorizer = DV(sparse=False)\n",
    "vec_x_cat = vectorizer.fit_transform(x_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 50)"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine them back\n",
    "x = np.hstack((x_num, vec_x_cat))\n",
    "df_scaled = pd.DataFrame(x, index=df.index)\n",
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6808, 35)"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title to Land has 7 values\n",
      "District has 27 values\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# create list of scaled columns\n",
    "columns_scaled = numeric_cols.copy()\n",
    "columns_scaled.append('GST Incl')\n",
    "#\n",
    "val_cnt_tot = 0\n",
    "val_cnt = len(df['Title to Land'].value_counts())\n",
    "val_cnt_tot += val_cnt\n",
    "print(''.join(['Title to Land', ' has ', str(val_cnt), ' values']))\n",
    "for i in range(val_cnt):\n",
    "    columns_scaled.append(' '.join(['Title to Land', str(i)]))\n",
    "val_cnt = len(df['District'].value_counts())\n",
    "distrs = df['District'].value_counts()\n",
    "val_cnt_tot += val_cnt\n",
    "print(''.join(['District', ' has ', str(val_cnt), ' values']))\n",
    "for ind in distrs.index:\n",
    "    columns_scaled.append(' '.join(['District', str(ind)]))\n",
    "print(val_cnt_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_scaled.columns = columns_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'DOM' and , 'Address_IsPH' columns\n",
    "df_scaled['DOM'] = df['DOM']\n",
    "df_scaled['Address_IsPH'] = df['Address_IsPH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PicCount</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Tot BR</th>\n",
       "      <th>Tot Baths</th>\n",
       "      <th>TotFlArea</th>\n",
       "      <th>Age</th>\n",
       "      <th>TotalPrkng</th>\n",
       "      <th># Rms</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>...</th>\n",
       "      <th>District 12</th>\n",
       "      <th>District 25</th>\n",
       "      <th>District 4</th>\n",
       "      <th>District 32</th>\n",
       "      <th>District 5</th>\n",
       "      <th>District 23</th>\n",
       "      <th>District 19</th>\n",
       "      <th>District 2</th>\n",
       "      <th>DOM</th>\n",
       "      <th>Address_IsPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2050687</th>\n",
       "      <td>-2.302161</td>\n",
       "      <td>-0.861236</td>\n",
       "      <td>-0.914670</td>\n",
       "      <td>-0.657683</td>\n",
       "      <td>-0.807609</td>\n",
       "      <td>-0.862037</td>\n",
       "      <td>-0.520211</td>\n",
       "      <td>-0.127012</td>\n",
       "      <td>-1.111587</td>\n",
       "      <td>1.527118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2050161</th>\n",
       "      <td>-2.643100</td>\n",
       "      <td>-0.344493</td>\n",
       "      <td>-0.385520</td>\n",
       "      <td>0.869434</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.213822</td>\n",
       "      <td>-0.287701</td>\n",
       "      <td>-0.127012</td>\n",
       "      <td>0.155713</td>\n",
       "      <td>1.527118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2049384</th>\n",
       "      <td>0.766285</td>\n",
       "      <td>-0.038619</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>0.869434</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.086644</td>\n",
       "      <td>0.099816</td>\n",
       "      <td>-0.127012</td>\n",
       "      <td>0.155713</td>\n",
       "      <td>1.527118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PicCount  List Price  Sold Price    Tot BR  Tot Baths  TotFlArea  \\\n",
       "R2050687 -2.302161   -0.861236   -0.914670 -0.657683  -0.807609  -0.862037   \n",
       "R2050161 -2.643100   -0.344493   -0.385520  0.869434   0.947883   0.213822   \n",
       "R2049384  0.766285   -0.038619    0.480363  0.869434   0.947883   0.086644   \n",
       "\n",
       "               Age  TotalPrkng     # Rms  Fireplaces      ...       \\\n",
       "R2050687 -0.520211   -0.127012 -1.111587    1.527118      ...        \n",
       "R2050161 -0.287701   -0.127012  0.155713    1.527118      ...        \n",
       "R2049384  0.099816   -0.127012  0.155713    1.527118      ...        \n",
       "\n",
       "          District 12  District 25  District 4  District 32  District 5  \\\n",
       "R2050687          1.0          0.0         1.0          0.0         0.0   \n",
       "R2050161          1.0          0.0         1.0          0.0         0.0   \n",
       "R2049384          1.0          0.0         1.0          0.0         0.0   \n",
       "\n",
       "          District 23  District 19  District 2  DOM  Address_IsPH  \n",
       "R2050687          0.0          0.0         0.0    0             0  \n",
       "R2050161          0.0          0.0         0.0    5             1  \n",
       "R2049384          0.0          0.0         0.0    3             0  \n",
       "\n",
       "[3 rows x 52 columns]"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv('data/df_52feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
